{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Example Wrangler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from wrangler import Wrangler\n",
    "from wrangler.data import PandasDataset, CSVDataset\n",
    "import wrangler.transformers as tr\n",
    "import wrangler.transformers.text as text_tr\n",
    "import wrangler.transformers.ml as ml_tr\n",
    "from wrangler import logger as wrangler_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Uncomment for console logging \n",
    "# wrangler_logger.enable()\n",
    "wrangler_logger.disable()\n",
    "# wrangler_logger.disable()\n",
    "# wrangler_logger.enable()\n",
    "\n",
    "# Uncomment for file output logging\n",
    "# wlogger.enable_file(filename='logfile.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-08 at 10:51:48 | INFO | catalog | Adding dataset: intermediate\n",
      "2022-02-08 at 10:51:48 | INFO | catalog | Adding dataset: dataset1\n",
      "2022-02-08 at 10:51:48 | INFO | catalog | Adding dataset: dataset2\n",
      "2022-02-08 at 10:51:48 | INFO | pipeline | Node primer nodo added to Pipeline \n",
      "2022-02-08 at 10:51:48 | INFO | pipeline | Node node_1 added to Pipeline \n",
      "2022-02-08 at 10:51:48 | INFO | pipeline | Node node_2 added to Pipeline \n",
      "2022-02-08 at 10:51:48 | INFO | pipeline | Node node_3 added to Pipeline \n",
      "2022-02-08 at 10:51:48 | INFO | pipeline | Node node_4 added to Pipeline \n"
     ]
    }
   ],
   "source": [
    "# Creamos el Wrangler\n",
    "wrangler = Wrangler()\n",
    "\n",
    "# Definimos Datasets\n",
    "df_b = pd.DataFrame({\"letras_b\":[\"d\", \"e\", \"f\", \"g\"],\n",
    "                    'tipo_b':['consonante','vocal','consonante','consonante'],\n",
    "                     \"numeros_b\":[3, 4, 5, 6]})\n",
    "\n",
    "\n",
    "\n",
    "dataset1 = CSVDataset(name='dataset1', filename='../data/dataset1.csv', save_params={'index':False})\n",
    "dataset2 = PandasDataset(name='dataset2', data=df_b)\n",
    "\n",
    "# Agregamos Datasets al Wrangler\n",
    "wrangler.add_dataset(dataset1)\n",
    "\n",
    "wrangler.add_dataset(dataset2)\n",
    "\n",
    "# Agregamos Nodos al Wrangler\n",
    "wrangler.add_node(\n",
    "    name= 'primer nodo',\n",
    "    transformer = tr.JoinTransformer(left_on='letras_a', right_on='letras_b', how='outer'),\n",
    "    inputs = ['dataset1','dataset2'],\n",
    "    outputs='dataset3'    \n",
    ")\n",
    "\n",
    "\n",
    "wrangler.add_node(\n",
    "    transformer=tr.ColumnDropper(columns=['numeros_b']),\n",
    "    inputs = 'dataset3'\n",
    "    # Si no especificamos un output Wrangler \n",
    "    # asigna un dataset 'intermediate' automaticamente\n",
    ")\n",
    "\n",
    "wrangler.add_node(\n",
    "    transformer=tr.DataCheckPoint('../data/checkpoint.csv'),  \n",
    "    # Si no especificamos ni inputs ni outputs\n",
    "    # Wrangler utiliza el dataset 'intermediate' como ambos.\n",
    ")\n",
    "\n",
    "wrangler.add_node(\n",
    "    transformer=text_tr.ModeImputer(column='tipo_a'),\n",
    ")\n",
    "\n",
    "wrangler.add_node(\n",
    "    transformer=text_tr.OrdinalEncoderTransformer(columns=['tipo_a']),\n",
    "    outputs='abt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-08 at 10:51:50 | INFO | node | Running Node: primer nodo\n",
      "2022-02-08 at 10:51:50 | INFO | catalog | Loading dataset: dataset1\n",
      "2022-02-08 at 10:51:50 | DEBUG | base | Loading CSVDataset(name='dataset1', filename='../data/dataset1.csv', save_params=dict)\n",
      "2022-02-08 at 10:51:51 | INFO | catalog | Loading dataset: dataset2\n",
      "2022-02-08 at 10:51:51 | DEBUG | base | Loading PandasDataset(name='dataset2', data=DataFrame)\n",
      "2022-02-08 at 10:51:51 | DEBUG | base | Fitting JoinTransformer(how='outer', left_on='letras_a', right_on='letras_b', left_index=False, right_index=False, suffixes=tuple, merge_kwargs=dict)\n",
      "2022-02-08 at 10:51:51 | DEBUG | base | Transforming JoinTransformer(how='outer', left_on='letras_a', right_on='letras_b', left_index=False, right_index=False, suffixes=tuple, merge_kwargs=dict)\n",
      "2022-02-08 at 10:51:51 | INFO | catalog | Saving dataset: dataset3\n",
      "2022-02-08 at 10:51:51 | INFO | catalog | Adding dataset: dataset3\n",
      "2022-02-08 at 10:51:51 | INFO | node | Running Node: node_1\n",
      "2022-02-08 at 10:51:51 | INFO | catalog | Loading dataset: dataset3\n",
      "2022-02-08 at 10:51:51 | DEBUG | base | Loading PandasDataset(name='dataset3', data=DataFrame)\n",
      "2022-02-08 at 10:51:51 | DEBUG | base | Fitting ColumnDropper(columns=['numeros_b'])\n",
      "2022-02-08 at 10:51:51 | DEBUG | base | Transforming ColumnDropper(columns=['numeros_b'])\n",
      "2022-02-08 at 10:51:51 | INFO | catalog | Saving dataset: intermediate\n",
      "2022-02-08 at 10:51:51 | DEBUG | base | Saving PandasDataset(name='intermediate', data=DataFrame)\n",
      "2022-02-08 at 10:51:51 | INFO | node | Running Node: node_2\n",
      "2022-02-08 at 10:51:51 | INFO | catalog | Loading dataset: intermediate\n",
      "2022-02-08 at 10:51:51 | DEBUG | base | Loading PandasDataset(name='intermediate', data=DataFrame)\n",
      "2022-02-08 at 10:51:51 | DEBUG | base | Fitting DataCheckPoint(save_path='../data/checkpoint.csv')\n",
      "2022-02-08 at 10:51:51 | DEBUG | base | Transforming DataCheckPoint(save_path='../data/checkpoint.csv')\n",
      "2022-02-08 at 10:51:52 | INFO | catalog | Saving dataset: intermediate\n",
      "2022-02-08 at 10:51:52 | DEBUG | base | Saving PandasDataset(name='intermediate', data=DataFrame)\n",
      "2022-02-08 at 10:51:52 | INFO | node | Running Node: node_3\n",
      "2022-02-08 at 10:51:52 | INFO | catalog | Loading dataset: intermediate\n",
      "2022-02-08 at 10:51:52 | DEBUG | base | Loading PandasDataset(name='intermediate', data=DataFrame)\n",
      "2022-02-08 at 10:51:52 | DEBUG | base | Fitting ModeImputer(column='tipo_a')\n",
      "2022-02-08 at 10:51:52 | DEBUG | base | Transforming ModeImputer(column='tipo_a', impute_value='consonante')\n",
      "2022-02-08 at 10:51:52 | INFO | catalog | Saving dataset: intermediate\n",
      "2022-02-08 at 10:51:52 | DEBUG | base | Saving PandasDataset(name='intermediate', data=DataFrame)\n",
      "2022-02-08 at 10:51:52 | INFO | node | Running Node: node_4\n",
      "2022-02-08 at 10:51:52 | INFO | catalog | Loading dataset: intermediate\n",
      "2022-02-08 at 10:51:52 | DEBUG | base | Loading PandasDataset(name='intermediate', data=DataFrame)\n",
      "2022-02-08 at 10:51:52 | DEBUG | base | Fitting OrdinalEncoderTransformer(columns=['tipo_a'])\n",
      "2022-02-08 at 10:51:52 | DEBUG | base | Transforming OrdinalEncoderTransformer(columns=['tipo_a'], encoder=OrdinalEncoder)\n",
      "2022-02-08 at 10:51:52 | INFO | catalog | Saving dataset: abt\n",
      "2022-02-08 at 10:51:52 | INFO | catalog | Adding dataset: abt\n"
     ]
    }
   ],
   "source": [
    "# Fiteamos los nodos\n",
    "wrangler.fit_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-08 at 17:32:10 | INFO | catalog | Loading dataset: abt\n",
      "2022-02-08 at 17:32:10 | DEBUG | base | Loading PandasDataset(name='abt', data=DataFrame)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numeros_a</th>\n",
       "      <th>numeros_c</th>\n",
       "      <th>letras_a</th>\n",
       "      <th>nombres</th>\n",
       "      <th>tipo_a</th>\n",
       "      <th>letras_b</th>\n",
       "      <th>tipo_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>a</td>\n",
       "      <td>codri</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>b</td>\n",
       "      <td>mafi</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>c</td>\n",
       "      <td>fredi</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>d</td>\n",
       "      <td>v3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>d</td>\n",
       "      <td>consonante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>e</td>\n",
       "      <td>tom</td>\n",
       "      <td>1.0</td>\n",
       "      <td>e</td>\n",
       "      <td>vocal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>f</td>\n",
       "      <td>agus</td>\n",
       "      <td>0.0</td>\n",
       "      <td>f</td>\n",
       "      <td>consonante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>g</td>\n",
       "      <td>sofi</td>\n",
       "      <td>0.0</td>\n",
       "      <td>g</td>\n",
       "      <td>consonante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>h</td>\n",
       "      <td>fredi</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>i</td>\n",
       "      <td>nahuel</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>j</td>\n",
       "      <td>emi</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   numeros_a  numeros_c letras_a nombres  tipo_a letras_b      tipo_b\n",
       "0          1         11        a   codri     1.0      NaN         NaN\n",
       "1          2         12        b    mafi     0.0      NaN         NaN\n",
       "2          3         13        c   fredi     0.0      NaN         NaN\n",
       "3          4         14        d      v3     0.0        d  consonante\n",
       "4          5         15        e     tom     1.0        e       vocal\n",
       "5          6         16        f    agus     0.0        f  consonante\n",
       "6          7         17        g    sofi     0.0        g  consonante\n",
       "7          8         18        h   fredi     0.0      NaN         NaN\n",
       "8          9         19        i  nahuel     1.0      NaN         NaN\n",
       "9         10         20        j     emi     0.0      NaN         NaN"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Leemos el dataset resultante\n",
    "# wrangler.data_catalog.load('abt')\n",
    "wrangler.data_catalog.load('abt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos el Wrangler fiteado\n",
    "# Solo se guardaran los datasets que no esten en memoria\n",
    "# es decir, solo los que no sean del tipo PandasDataset\n",
    "wrangler.save('../data/basic_example_wrangler')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-08 at 10:52:47 | INFO | catalog | Adding dataset: intermediate\n"
     ]
    }
   ],
   "source": [
    "# Creamos un nuevo Wrangler vacio\n",
    "new_wrangler = Wrangler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_wrangler.load('../data/basic_example_wrangler')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset1': CSVDataset(name='dataset1', filename='../data/dataset1.csv', save_params=dict)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_wrangler.data_catalog.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset1', 'dataset2'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# El Wrangler necesita dataset1 y dataset2 para ejecutar\n",
    "new_wrangler.pipeline.inputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-08 at 10:53:09 | INFO | catalog | Adding dataset: dataset1\n",
      "2022-02-08 at 10:53:09 | INFO | catalog | Adding dataset: dataset2\n"
     ]
    }
   ],
   "source": [
    "df_a_test = pd.DataFrame({\n",
    "    \"letras_a\":[\"h\", \"i\", \"j\", \"j\", \"l\", \"m\",'n'],\n",
    "    'tipo_a':['consonante','vocal','consonante','consonante','consonante','consonante',np.NaN],\n",
    "    \"numeros_a\":[1, 2, 3, 4, 5, 6, np.NaN]\n",
    "                     })\n",
    "\n",
    "\n",
    "df_b_test = pd.DataFrame({\n",
    "    \"letras_b\":[\"o\", \"p\", \"q\", \"r\"],\n",
    "    'tipo_b':['vocal','consonante','consonante','consonante'],\n",
    "    \"numeros_b\":[3, 4, 5, 6]\n",
    "                     })\n",
    "\n",
    "dataset_test1 = PandasDataset('dataset1',df_a_test)\n",
    "dataset_test2 = PandasDataset('dataset2',df_b_test)\n",
    "\n",
    "# Agregamos/Sobreescribimos los nuevos dataset1 y dataset2\n",
    "new_wrangler.add_dataset(dataset_test1)\n",
    "new_wrangler.add_dataset(dataset_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-08 at 10:53:11 | INFO | node | Running Node: primer nodo\n",
      "2022-02-08 at 10:53:11 | INFO | catalog | Loading dataset: dataset1\n",
      "2022-02-08 at 10:53:11 | DEBUG | base | Loading PandasDataset(name='dataset1', data=DataFrame)\n",
      "2022-02-08 at 10:53:11 | INFO | catalog | Loading dataset: dataset2\n",
      "2022-02-08 at 10:53:11 | DEBUG | base | Loading PandasDataset(name='dataset2', data=DataFrame)\n",
      "2022-02-08 at 10:53:11 | DEBUG | base | Transforming JoinTransformer(how='outer', left_on='letras_a', right_on='letras_b', left_index=False, right_index=False, suffixes=tuple, merge_kwargs=dict)\n",
      "2022-02-08 at 10:53:11 | INFO | catalog | Saving dataset: dataset3\n",
      "2022-02-08 at 10:53:11 | INFO | catalog | Adding dataset: dataset3\n",
      "2022-02-08 at 10:53:11 | INFO | node | Running Node: node_1\n",
      "2022-02-08 at 10:53:11 | INFO | catalog | Loading dataset: dataset3\n",
      "2022-02-08 at 10:53:11 | DEBUG | base | Loading PandasDataset(name='dataset3', data=DataFrame)\n",
      "2022-02-08 at 10:53:11 | DEBUG | base | Transforming ColumnDropper(columns=['numeros_b'])\n",
      "2022-02-08 at 10:53:11 | INFO | catalog | Saving dataset: intermediate\n",
      "2022-02-08 at 10:53:11 | INFO | catalog | Adding dataset: intermediate\n",
      "2022-02-08 at 10:53:11 | INFO | node | Running Node: node_2\n",
      "2022-02-08 at 10:53:11 | INFO | catalog | Loading dataset: intermediate\n",
      "2022-02-08 at 10:53:11 | DEBUG | base | Loading PandasDataset(name='intermediate', data=DataFrame)\n",
      "2022-02-08 at 10:53:11 | DEBUG | base | Transforming DataCheckPoint(save_path='../data/checkpoint.csv')\n",
      "2022-02-08 at 10:53:11 | INFO | catalog | Saving dataset: intermediate\n",
      "2022-02-08 at 10:53:11 | DEBUG | base | Saving PandasDataset(name='intermediate', data=DataFrame)\n",
      "2022-02-08 at 10:53:11 | INFO | node | Running Node: node_3\n",
      "2022-02-08 at 10:53:11 | INFO | catalog | Loading dataset: intermediate\n",
      "2022-02-08 at 10:53:11 | DEBUG | base | Loading PandasDataset(name='intermediate', data=DataFrame)\n",
      "2022-02-08 at 10:53:11 | DEBUG | base | Transforming ModeImputer(column='tipo_a', impute_value='consonante')\n",
      "2022-02-08 at 10:53:11 | INFO | catalog | Saving dataset: intermediate\n",
      "2022-02-08 at 10:53:11 | DEBUG | base | Saving PandasDataset(name='intermediate', data=DataFrame)\n",
      "2022-02-08 at 10:53:11 | INFO | node | Running Node: node_4\n",
      "2022-02-08 at 10:53:11 | INFO | catalog | Loading dataset: intermediate\n",
      "2022-02-08 at 10:53:11 | DEBUG | base | Loading PandasDataset(name='intermediate', data=DataFrame)\n",
      "2022-02-08 at 10:53:11 | DEBUG | base | Transforming OrdinalEncoderTransformer(columns=['tipo_a'], encoder=OrdinalEncoder)\n",
      "2022-02-08 at 10:53:11 | INFO | catalog | Saving dataset: abt\n",
      "2022-02-08 at 10:53:11 | INFO | catalog | Adding dataset: abt\n"
     ]
    }
   ],
   "source": [
    "# Aplicamos las transformaciones predefinidas \n",
    "new_wrangler.transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-08 at 10:53:15 | INFO | catalog | Loading dataset: abt\n",
      "2022-02-08 at 10:53:15 | DEBUG | base | Loading PandasDataset(name='abt', data=DataFrame)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>letras_a</th>\n",
       "      <th>tipo_a</th>\n",
       "      <th>numeros_a</th>\n",
       "      <th>letras_b</th>\n",
       "      <th>tipo_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>h</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>j</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>j</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>l</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>m</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>n</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>o</td>\n",
       "      <td>vocal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>p</td>\n",
       "      <td>consonante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>q</td>\n",
       "      <td>consonante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>r</td>\n",
       "      <td>consonante</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   letras_a  tipo_a  numeros_a letras_b      tipo_b\n",
       "0         h     0.0        1.0      NaN         NaN\n",
       "1         i     1.0        2.0      NaN         NaN\n",
       "2         j     0.0        3.0      NaN         NaN\n",
       "3         j     0.0        4.0      NaN         NaN\n",
       "4         l     0.0        5.0      NaN         NaN\n",
       "5         m     0.0        6.0      NaN         NaN\n",
       "6         n     0.0        NaN      NaN         NaN\n",
       "7       NaN     0.0        NaN        o       vocal\n",
       "8       NaN     0.0        NaN        p  consonante\n",
       "9       NaN     0.0        NaN        q  consonante\n",
       "10      NaN     0.0        NaN        r  consonante"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_wrangler.data_catalog.load('abt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Generated by graphviz version 2.49.3 (20211023.0002)\r\n -->\r\n<!-- Title: wrangler Pages: 1 -->\r\n<svg width=\"1296pt\" height=\"1065pt\"\r\n viewBox=\"0.00 0.00 1296.00 1064.81\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1.36 1.36) rotate(0) translate(4 779)\">\r\n<title>wrangler</title>\r\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-779 949,-779 949,4 -4,4\"/>\r\n<!-- node_data_i_0 -->\r\n<g id=\"node1\" class=\"node\">\r\n<title>node_data_i_0</title>\r\n<polygon fill=\"none\" stroke=\"black\" points=\"77,-728.5 77,-774.5 464,-774.5 464,-728.5 77,-728.5\"/>\r\n<text text-anchor=\"middle\" x=\"98\" y=\"-747.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Data</text>\r\n<polyline fill=\"none\" stroke=\"black\" points=\"119,-728.5 119,-774.5 \"/>\r\n<text text-anchor=\"middle\" x=\"143.5\" y=\"-759.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Name</text>\r\n<polyline fill=\"none\" stroke=\"black\" points=\"119,-751.5 168,-751.5 \"/>\r\n<text text-anchor=\"middle\" x=\"143.5\" y=\"-736.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Type</text>\r\n<polyline fill=\"none\" stroke=\"black\" points=\"168,-728.5 168,-774.5 \"/>\r\n<text text-anchor=\"middle\" x=\"316\" y=\"-759.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">dataset1</text>\r\n<polyline fill=\"none\" stroke=\"black\" points=\"168,-751.5 464,-751.5 \"/>\r\n<text text-anchor=\"middle\" x=\"316\" y=\"-736.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">PandasDataset(name=&#39;dataset1&#39;, data=DataFrame)</text>\r\n</g>\r\n<!-- node0 -->\r\n<g id=\"node4\" class=\"node\">\r\n<title>node0</title>\r\n<polygon fill=\"none\" stroke=\"black\" points=\"0,-599.5 0,-691.5 945,-691.5 945,-599.5 0,-599.5\"/>\r\n<text text-anchor=\"middle\" x=\"23.5\" y=\"-641.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Node</text>\r\n<polyline fill=\"none\" stroke=\"black\" points=\"47,-599.5 47,-691.5 \"/>\r\n<text text-anchor=\"middle\" x=\"90\" y=\"-676.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Name</text>\r\n<polyline fill=\"none\" stroke=\"black\" points=\"47,-668.5 133,-668.5 \"/>\r\n<text text-anchor=\"middle\" x=\"90\" y=\"-653.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Transformer</text>\r\n<polyline fill=\"none\" stroke=\"black\" points=\"47,-645.5 133,-645.5 \"/>\r\n<text text-anchor=\"middle\" x=\"90\" y=\"-630.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Inputs</text>\r\n<polyline fill=\"none\" stroke=\"black\" points=\"47,-622.5 133,-622.5 \"/>\r\n<text text-anchor=\"middle\" x=\"90\" y=\"-607.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Outputs</text>\r\n<polyline fill=\"none\" stroke=\"black\" points=\"133,-599.5 133,-691.5 \"/>\r\n<text text-anchor=\"middle\" x=\"539\" y=\"-676.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">primer nodo</text>\r\n<polyline fill=\"none\" stroke=\"black\" points=\"133,-668.5 945,-668.5 \"/>\r\n<text text-anchor=\"middle\" x=\"539\" y=\"-653.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">JoinTransformer(how=&#39;outer&#39;, left_on=&#39;letras_a&#39;, right_on=&#39;letras_b&#39;, left_index=False, right_index=False, suffixes=tuple, merge_kwargs=dict)</text>\r\n<polyline fill=\"none\" stroke=\"black\" points=\"133,-645.5 945,-645.5 \"/>\r\n<text text-anchor=\"middle\" x=\"539\" y=\"-630.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">[&#39;dataset1&#39;, &#39;dataset2&#39;]</text>\r\n<polyline fill=\"none\" stroke=\"black\" points=\"133,-622.5 945,-622.5 \"/>\r\n<text text-anchor=\"middle\" x=\"539\" y=\"-607.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">[&#39;dataset3&#39;]</text>\r\n</g>\r\n<!-- node_data_i_0&#45;&gt;node0 -->\r\n<g id=\"edge1\" class=\"edge\">\r\n<title>node_data_i_0&#45;&gt;node0</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M313.34,-728.44C331.66,-719.01 353.86,-707.58 375.78,-696.3\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"377.53,-699.33 384.82,-691.64 374.32,-693.11 377.53,-699.33\"/>\r\n</g>\r\n<!-- node_data_i_1 -->\r\n<g id=\"node2\" class=\"node\">\r\n<title>node_data_i_1</title>\r\n<polygon fill=\"none\" stroke=\"black\" points=\"482,-728.5 482,-774.5 869,-774.5 869,-728.5 482,-728.5\"/>\r\n<text text-anchor=\"middle\" x=\"503\" y=\"-747.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Data</text>\r\n<polyline fill=\"none\" stroke=\"black\" points=\"524,-728.5 524,-774.5 \"/>\r\n<text text-anchor=\"middle\" x=\"548.5\" y=\"-759.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Name</text>\r\n<polyline fill=\"none\" stroke=\"black\" points=\"524,-751.5 573,-751.5 \"/>\r\n<text text-anchor=\"middle\" x=\"548.5\" y=\"-736.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Type</text>\r\n<polyline fill=\"none\" stroke=\"black\" points=\"573,-728.5 573,-774.5 \"/>\r\n<text text-anchor=\"middle\" x=\"721\" y=\"-759.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">dataset2</text>\r\n<polyline fill=\"none\" stroke=\"black\" points=\"573,-751.5 869,-751.5 \"/>\r\n<text text-anchor=\"middle\" x=\"721\" y=\"-736.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">PandasDataset(name=&#39;dataset2&#39;, data=DataFrame)</text>\r\n</g>\r\n<!-- node_data_i_1&#45;&gt;node0 -->\r\n<g id=\"edge2\" class=\"edge\">\r\n<title>node_data_i_1&#45;&gt;node0</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M632.45,-728.44C614.04,-719.01 591.73,-707.58 569.7,-696.3\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"571.11,-693.09 560.62,-691.64 567.92,-699.32 571.11,-693.09\"/>\r\n</g>\r\n<!-- node_data_o_0 -->\r\n<g id=\"node3\" class=\"node\">\r\n<title>node_data_o_0</title>\r\n<polygon fill=\"none\" stroke=\"black\" points=\"293,-0.5 293,-46.5 652,-46.5 652,-0.5 293,-0.5\"/>\r\n<text text-anchor=\"middle\" x=\"314\" y=\"-19.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Data</text>\r\n<polyline fill=\"none\" stroke=\"black\" points=\"335,-0.5 335,-46.5 \"/>\r\n<text text-anchor=\"middle\" x=\"359.5\" y=\"-31.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Name</text>\r\n<polyline fill=\"none\" stroke=\"black\" points=\"335,-23.5 384,-23.5 \"/>\r\n<text text-anchor=\"middle\" x=\"359.5\" y=\"-8.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Type</text>\r\n<polyline fill=\"none\" stroke=\"black\" points=\"384,-0.5 384,-46.5 \"/>\r\n<text text-anchor=\"middle\" x=\"518\" y=\"-31.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">abt</text>\r\n<polyline fill=\"none\" stroke=\"black\" points=\"384,-23.5 652,-23.5 \"/>\r\n<text text-anchor=\"middle\" x=\"518\" y=\"-8.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">PandasDataset(name=&#39;abt&#39;, data=DataFrame)</text>\r\n</g>\r\n<!-- node1 -->\r\n<g id=\"node5\" class=\"node\">\r\n<title>node1</title>\r\n<polygon fill=\"none\" stroke=\"black\" points=\"280.5,-470.5 280.5,-562.5 664.5,-562.5 664.5,-470.5 280.5,-470.5\"/>\r\n<text text-anchor=\"middle\" x=\"304\" y=\"-512.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Node</text>\r\n<polyline fill=\"none\" stroke=\"black\" points=\"327.5,-470.5 327.5,-562.5 \"/>\r\n<text text-anchor=\"middle\" x=\"370.5\" y=\"-547.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Name</text>\r\n<polyline fill=\"none\" stroke=\"black\" points=\"327.5,-539.5 413.5,-539.5 \"/>\r\n<text text-anchor=\"middle\" x=\"370.5\" y=\"-524.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Transformer</text>\r\n<polyline fill=\"none\" stroke=\"black\" points=\"327.5,-516.5 413.5,-516.5 \"/>\r\n<text text-anchor=\"middle\" x=\"370.5\" y=\"-501.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Inputs</text>\r\n<polyline fill=\"none\" stroke=\"black\" points=\"327.5,-493.5 413.5,-493.5 \"/>\r\n<text text-anchor=\"middle\" x=\"370.5\" y=\"-478.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Outputs</text>\r\n<polyline fill=\"none\" stroke=\"black\" points=\"413.5,-470.5 413.5,-562.5 \"/>\r\n<text text-anchor=\"middle\" x=\"539\" y=\"-547.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">node_1</text>\r\n<polyline fill=\"none\" stroke=\"black\" points=\"413.5,-539.5 664.5,-539.5 \"/>\r\n<text text-anchor=\"middle\" x=\"539\" y=\"-524.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">ColumnDropper(columns=[&#39;numeros_b&#39;])</text>\r\n<polyline fill=\"none\" stroke=\"black\" points=\"413.5,-516.5 664.5,-516.5 \"/>\r\n<text text-anchor=\"middle\" x=\"539\" y=\"-501.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">[&#39;dataset3&#39;]</text>\r\n<polyline fill=\"none\" stroke=\"black\" points=\"413.5,-493.5 664.5,-493.5 \"/>\r\n<text text-anchor=\"middle\" x=\"539\" y=\"-478.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">[&#39;intermediate&#39;]</text>\r\n</g>\r\n<!-- node0&#45;&gt;node1 -->\r\n<g id=\"edge6\" class=\"edge\">\r\n<title>node0&#45;&gt;node1</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M472.5,-599.37C472.5,-590.86 472.5,-581.87 472.5,-573.09\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"476,-572.92 472.5,-562.92 469,-572.92 476,-572.92\"/>\r\n</g>\r\n<!-- node2 -->\r\n<g id=\"node6\" class=\"node\">\r\n<title>node2</title>\r\n<polygon fill=\"none\" stroke=\"black\" points=\"251,-341.5 251,-433.5 694,-433.5 694,-341.5 251,-341.5\"/>\r\n<text text-anchor=\"middle\" x=\"274.5\" y=\"-383.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Node</text>\r\n<polyline fill=\"none\" stroke=\"black\" points=\"298,-341.5 298,-433.5 \"/>\r\n<text text-anchor=\"middle\" x=\"341\" y=\"-418.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Name</text>\r\n<polyline fill=\"none\" stroke=\"black\" points=\"298,-410.5 384,-410.5 \"/>\r\n<text text-anchor=\"middle\" x=\"341\" y=\"-395.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Transformer</text>\r\n<polyline fill=\"none\" stroke=\"black\" points=\"298,-387.5 384,-387.5 \"/>\r\n<text text-anchor=\"middle\" x=\"341\" y=\"-372.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Inputs</text>\r\n<polyline fill=\"none\" stroke=\"black\" points=\"298,-364.5 384,-364.5 \"/>\r\n<text text-anchor=\"middle\" x=\"341\" y=\"-349.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Outputs</text>\r\n<polyline fill=\"none\" stroke=\"black\" points=\"384,-341.5 384,-433.5 \"/>\r\n<text text-anchor=\"middle\" x=\"539\" y=\"-418.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">node_2</text>\r\n<polyline fill=\"none\" stroke=\"black\" points=\"384,-410.5 694,-410.5 \"/>\r\n<text text-anchor=\"middle\" x=\"539\" y=\"-395.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">DataCheckPoint(save_path=&#39;../data/checkpoint.csv&#39;)</text>\r\n<polyline fill=\"none\" stroke=\"black\" points=\"384,-387.5 694,-387.5 \"/>\r\n<text text-anchor=\"middle\" x=\"539\" y=\"-372.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">[&#39;intermediate&#39;]</text>\r\n<polyline fill=\"none\" stroke=\"black\" points=\"384,-364.5 694,-364.5 \"/>\r\n<text text-anchor=\"middle\" x=\"539\" y=\"-349.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">[&#39;intermediate&#39;]</text>\r\n</g>\r\n<!-- node1&#45;&gt;node2 -->\r\n<g id=\"edge5\" class=\"edge\">\r\n<title>node1&#45;&gt;node2</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M472.5,-470.37C472.5,-461.86 472.5,-452.87 472.5,-444.09\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"476,-443.92 472.5,-433.92 469,-443.92 476,-443.92\"/>\r\n</g>\r\n<!-- node3 -->\r\n<g id=\"node7\" class=\"node\">\r\n<title>node3</title>\r\n<polygon fill=\"none\" stroke=\"black\" points=\"230,-212.5 230,-304.5 715,-304.5 715,-212.5 230,-212.5\"/>\r\n<text text-anchor=\"middle\" x=\"253.5\" y=\"-254.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Node</text>\r\n<polyline fill=\"none\" stroke=\"black\" points=\"277,-212.5 277,-304.5 \"/>\r\n<text text-anchor=\"middle\" x=\"320\" y=\"-289.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Name</text>\r\n<polyline fill=\"none\" stroke=\"black\" points=\"277,-281.5 363,-281.5 \"/>\r\n<text text-anchor=\"middle\" x=\"320\" y=\"-266.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Transformer</text>\r\n<polyline fill=\"none\" stroke=\"black\" points=\"277,-258.5 363,-258.5 \"/>\r\n<text text-anchor=\"middle\" x=\"320\" y=\"-243.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Inputs</text>\r\n<polyline fill=\"none\" stroke=\"black\" points=\"277,-235.5 363,-235.5 \"/>\r\n<text text-anchor=\"middle\" x=\"320\" y=\"-220.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Outputs</text>\r\n<polyline fill=\"none\" stroke=\"black\" points=\"363,-212.5 363,-304.5 \"/>\r\n<text text-anchor=\"middle\" x=\"539\" y=\"-289.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">node_3</text>\r\n<polyline fill=\"none\" stroke=\"black\" points=\"363,-281.5 715,-281.5 \"/>\r\n<text text-anchor=\"middle\" x=\"539\" y=\"-266.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">ModeImputer(column=&#39;tipo_a&#39;, impute_value=&#39;consonante&#39;)</text>\r\n<polyline fill=\"none\" stroke=\"black\" points=\"363,-258.5 715,-258.5 \"/>\r\n<text text-anchor=\"middle\" x=\"539\" y=\"-243.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">[&#39;intermediate&#39;]</text>\r\n<polyline fill=\"none\" stroke=\"black\" points=\"363,-235.5 715,-235.5 \"/>\r\n<text text-anchor=\"middle\" x=\"539\" y=\"-220.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">[&#39;intermediate&#39;]</text>\r\n</g>\r\n<!-- node2&#45;&gt;node3 -->\r\n<g id=\"edge4\" class=\"edge\">\r\n<title>node2&#45;&gt;node3</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M472.5,-341.37C472.5,-332.86 472.5,-323.87 472.5,-315.09\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"476,-314.92 472.5,-304.92 469,-314.92 476,-314.92\"/>\r\n</g>\r\n<!-- node4 -->\r\n<g id=\"node8\" class=\"node\">\r\n<title>node4</title>\r\n<polygon fill=\"none\" stroke=\"black\" points=\"186.5,-83.5 186.5,-175.5 758.5,-175.5 758.5,-83.5 186.5,-83.5\"/>\r\n<text text-anchor=\"middle\" x=\"210\" y=\"-125.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Node</text>\r\n<polyline fill=\"none\" stroke=\"black\" points=\"233.5,-83.5 233.5,-175.5 \"/>\r\n<text text-anchor=\"middle\" x=\"276.5\" y=\"-160.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Name</text>\r\n<polyline fill=\"none\" stroke=\"black\" points=\"233.5,-152.5 319.5,-152.5 \"/>\r\n<text text-anchor=\"middle\" x=\"276.5\" y=\"-137.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Transformer</text>\r\n<polyline fill=\"none\" stroke=\"black\" points=\"233.5,-129.5 319.5,-129.5 \"/>\r\n<text text-anchor=\"middle\" x=\"276.5\" y=\"-114.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Inputs</text>\r\n<polyline fill=\"none\" stroke=\"black\" points=\"233.5,-106.5 319.5,-106.5 \"/>\r\n<text text-anchor=\"middle\" x=\"276.5\" y=\"-91.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Outputs</text>\r\n<polyline fill=\"none\" stroke=\"black\" points=\"319.5,-83.5 319.5,-175.5 \"/>\r\n<text text-anchor=\"middle\" x=\"539\" y=\"-160.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">node_4</text>\r\n<polyline fill=\"none\" stroke=\"black\" points=\"319.5,-152.5 758.5,-152.5 \"/>\r\n<text text-anchor=\"middle\" x=\"539\" y=\"-137.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">OrdinalEncoderTransformer(columns=[&#39;tipo_a&#39;], encoder=OrdinalEncoder)</text>\r\n<polyline fill=\"none\" stroke=\"black\" points=\"319.5,-129.5 758.5,-129.5 \"/>\r\n<text text-anchor=\"middle\" x=\"539\" y=\"-114.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">[&#39;intermediate&#39;]</text>\r\n<polyline fill=\"none\" stroke=\"black\" points=\"319.5,-106.5 758.5,-106.5 \"/>\r\n<text text-anchor=\"middle\" x=\"539\" y=\"-91.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">[&#39;abt&#39;]</text>\r\n</g>\r\n<!-- node3&#45;&gt;node4 -->\r\n<g id=\"edge3\" class=\"edge\">\r\n<title>node3&#45;&gt;node4</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M472.5,-212.37C472.5,-203.86 472.5,-194.87 472.5,-186.09\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"476,-185.92 472.5,-175.92 469,-185.92 476,-185.92\"/>\r\n</g>\r\n<!-- node4&#45;&gt;node_data_o_0 -->\r\n<g id=\"edge7\" class=\"edge\">\r\n<title>node4&#45;&gt;node_data_o_0</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M472.5,-83.49C472.5,-74.53 472.5,-65.3 472.5,-56.87\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"476,-56.7 472.5,-46.7 469,-56.7 476,-56.7\"/>\r\n</g>\r\n</g>\r\n</svg>\r\n",
      "text/plain": [
       "<graphviz.dot.Digraph at 0x1d1f3c47cd0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from wrangler.extras import plot_wrangler\n",
    "\n",
    "plot_wrangler(new_wrangler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wrangler.wrangler.Wrangler at 0x1d1f3c47940>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exportamos la configuracion de los datasets a un .yaml para poder modificarlos\n",
    "new_wrangler.datasets_to_config(\"../data/basic_example_datasets.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-08 at 10:54:52 | INFO | catalog | Adding dataset: intermediate\n"
     ]
    }
   ],
   "source": [
    "# levantamos un wrangler nuevo\n",
    "new_wrangler2 = Wrangler()\n",
    "\n",
    "new_wrangler2.load('../data/basic_example_wrangler')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-08 at 10:54:53 | INFO | catalog | Adding dataset: dataset1\n",
      "2022-02-08 at 10:54:53 | INFO | catalog | Adding dataset: dataset2\n",
      "2022-02-08 at 10:54:53 | INFO | catalog | Adding dataset: abt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<wrangler.wrangler.Wrangler at 0x1d1f59512b0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seteamos la configuracion de los datasets a partir del yaml\n",
    "new_wrangler2.datasets_from_config(\"../data/basic_example_datasets_new.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-08 at 10:54:57 | INFO | node | Running Node: primer nodo\n",
      "2022-02-08 at 10:54:57 | INFO | catalog | Loading dataset: dataset1\n",
      "2022-02-08 at 10:54:57 | DEBUG | base | Loading CSVDataset(name='dataset1', filename='../data/dataset1.csv')\n",
      "2022-02-08 at 10:54:57 | INFO | catalog | Loading dataset: dataset2\n",
      "2022-02-08 at 10:54:57 | DEBUG | base | Loading CSVDataset(name='dataset2', filename='../data/dataset2.csv')\n",
      "2022-02-08 at 10:54:58 | DEBUG | base | Transforming JoinTransformer(how='outer', left_on='letras_a', right_on='letras_b', left_index=False, right_index=False, suffixes=tuple, merge_kwargs=dict)\n",
      "2022-02-08 at 10:54:58 | INFO | catalog | Saving dataset: dataset3\n",
      "2022-02-08 at 10:54:58 | INFO | catalog | Adding dataset: dataset3\n",
      "2022-02-08 at 10:54:58 | INFO | node | Running Node: node_1\n",
      "2022-02-08 at 10:54:58 | INFO | catalog | Loading dataset: dataset3\n",
      "2022-02-08 at 10:54:58 | DEBUG | base | Loading PandasDataset(name='dataset3', data=DataFrame)\n",
      "2022-02-08 at 10:54:58 | DEBUG | base | Transforming ColumnDropper(columns=['numeros_b'])\n",
      "2022-02-08 at 10:54:58 | INFO | catalog | Saving dataset: intermediate\n",
      "2022-02-08 at 10:54:58 | INFO | catalog | Adding dataset: intermediate\n",
      "2022-02-08 at 10:54:58 | INFO | node | Running Node: node_2\n",
      "2022-02-08 at 10:54:58 | INFO | catalog | Loading dataset: intermediate\n",
      "2022-02-08 at 10:54:58 | DEBUG | base | Loading PandasDataset(name='intermediate', data=DataFrame)\n",
      "2022-02-08 at 10:54:58 | DEBUG | base | Transforming DataCheckPoint(save_path='../data/checkpoint.csv')\n",
      "2022-02-08 at 10:54:58 | INFO | catalog | Saving dataset: intermediate\n",
      "2022-02-08 at 10:54:58 | DEBUG | base | Saving PandasDataset(name='intermediate', data=DataFrame)\n",
      "2022-02-08 at 10:54:58 | INFO | node | Running Node: node_3\n",
      "2022-02-08 at 10:54:58 | INFO | catalog | Loading dataset: intermediate\n",
      "2022-02-08 at 10:54:58 | DEBUG | base | Loading PandasDataset(name='intermediate', data=DataFrame)\n",
      "2022-02-08 at 10:54:58 | DEBUG | base | Transforming ModeImputer(column='tipo_a', impute_value='consonante')\n",
      "2022-02-08 at 10:54:58 | INFO | catalog | Saving dataset: intermediate\n",
      "2022-02-08 at 10:54:58 | DEBUG | base | Saving PandasDataset(name='intermediate', data=DataFrame)\n",
      "2022-02-08 at 10:54:58 | INFO | node | Running Node: node_4\n",
      "2022-02-08 at 10:54:58 | INFO | catalog | Loading dataset: intermediate\n",
      "2022-02-08 at 10:54:58 | DEBUG | base | Loading PandasDataset(name='intermediate', data=DataFrame)\n",
      "2022-02-08 at 10:54:58 | DEBUG | base | Transforming OrdinalEncoderTransformer(columns=['tipo_a'], encoder=OrdinalEncoder)\n",
      "2022-02-08 at 10:54:58 | INFO | catalog | Saving dataset: abt\n",
      "2022-02-08 at 10:54:58 | DEBUG | base | Saving CSVDataset(name='abt', filename='../data/basic_example_abt.csv')\n"
     ]
    }
   ],
   "source": [
    "new_wrangler2.transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "477c64429a66b88dbea596d2fd7dadb0d3a75c4333ee684689ddf8e8bb5bf8be"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
